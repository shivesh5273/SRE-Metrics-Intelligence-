{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import + Folders\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, mean_absolute_error, mean_squared_error"
   ],
   "id": "fbc121e30a2defb3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# âœ… EDIT THIS:\n",
    "# Point this to the folder where you unzipped the Kaggle NAB dataset.\n",
    "# Example:\n",
    "# NAB_ROOT = Path(r\"/Users/you/Downloads/nab\")\n",
    "NAB_ROOT = Path(r\"PUT_YOUR_UNZIPPED_NAB_FOLDER_PATH_HERE\")\n",
    "\n",
    "assert NAB_ROOT.exists(), f\"NAB_ROOT does not exist: {NAB_ROOT}\"\n",
    "\n",
    "# Project output folders (in your repo)\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "ARTIFACTS_DIR = PROJECT_ROOT / \"artifacts\"\n",
    "IMAGES_DIR = PROJECT_ROOT / \"images\"\n",
    "for d in [DATA_DIR, ARTIFACTS_DIR, IMAGES_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"NAB_ROOT:\", NAB_ROOT)\n",
    "print(\"Outputs:\", DATA_DIR, ARTIFACTS_DIR, IMAGES_DIR)"
   ],
   "id": "8a84c04d40f2648b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Discover a good AWS CloudWatch time series\n",
    "# NAB commonly has: data/realAWSCloudwatch/*.csv\n",
    "candidate_dir = None\n",
    "\n",
    "# try common layouts (Kaggle zip may already have these paths)\n",
    "for p in [\n",
    "    NAB_ROOT / \"data\" / \"realAWSCloudwatch\",\n",
    "    NAB_ROOT / \"realAWSCloudwatch\",\n",
    "    NAB_ROOT / \"data\" / \"realAWSCloudwatch\".lower(),  # just in case\n",
    "]:\n",
    "    if p.exists():\n",
    "        candidate_dir = p\n",
    "        break\n",
    "\n",
    "assert candidate_dir is not None, \"Could not find realAWSCloudwatch folder under NAB_ROOT.\"\n",
    "\n",
    "csv_files = sorted(candidate_dir.glob(\"*.csv\"))\n",
    "assert len(csv_files) > 0, f\"No CSVs found in {candidate_dir}\"\n",
    "\n",
    "print(f\"Found {len(csv_files)} AWS CloudWatch CSV files in:\\n  {candidate_dir}\\n\")\n",
    "print(\"Sample files:\")\n",
    "for f in csv_files[:10]:\n",
    "    print(\" -\", f.name)\n",
    "\n",
    "# Pick one \"good\" file automatically: prefer CPU utilization, else first file\n",
    "preferred = [f for f in csv_files if \"cpu_utilization\" in f.name.lower()]\n",
    "series_path = preferred[0] if preferred else csv_files[0]\n",
    "print(\"\\nSelected series:\", series_path.name)"
   ],
   "id": "4194a3a31d8ccce2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load the CSV robustly (auto-detect timestamp/value)\n",
    "def load_nab_csv(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    NAB CSVs are typically two columns: timestamp,value\n",
    "    but we auto-detect to be safe.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # If header exists and looks like timestamp/value\n",
    "    cols = [c.lower() for c in df.columns]\n",
    "    if \"timestamp\" in cols:\n",
    "        ts_col = df.columns[cols.index(\"timestamp\")]\n",
    "    else:\n",
    "        ts_col = df.columns[0]\n",
    "\n",
    "    if \"value\" in cols:\n",
    "        val_col = df.columns[cols.index(\"value\")]\n",
    "    else:\n",
    "        # assume second column is the series value\n",
    "        val_col = df.columns[1] if len(df.columns) > 1 else df.columns[0]\n",
    "\n",
    "    out = df[[ts_col, val_col]].copy()\n",
    "    out.columns = [\"timestamp\", \"value\"]\n",
    "\n",
    "    out[\"timestamp\"] = pd.to_datetime(out[\"timestamp\"], errors=\"coerce\", utc=True)\n",
    "    out = out.dropna(subset=[\"timestamp\", \"value\"])\n",
    "    out = out.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "    # ensure numeric values\n",
    "    out[\"value\"] = pd.to_numeric(out[\"value\"], errors=\"coerce\")\n",
    "    out = out.dropna(subset=[\"value\"])\n",
    "\n",
    "    out = out.set_index(\"timestamp\")\n",
    "    return out\n",
    "\n",
    "ts = load_nab_csv(series_path)\n",
    "print(ts.head())\n",
    "print(\"\\nRows:\", len(ts))\n",
    "print(\"Index tz:\", ts.index.tz)"
   ],
   "id": "e6fdb63d95f001a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load anomaly windows (ground truth) from NAB labels\n",
    "def find_combined_windows_json(root: Path) -> Path:\n",
    "    candidates = [\n",
    "        root / \"labels\" / \"combined_windows.json\",\n",
    "        root / \"nab\" / \"labels\" / \"combined_windows.json\",\n",
    "        root / \"combined_windows.json\",\n",
    "        root / \"labels\" / \"combined_windows.json\".lower(),\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if c.exists():\n",
    "            return c\n",
    "    raise FileNotFoundError(\"Could not find labels/combined_windows.json under NAB_ROOT.\")\n",
    "\n",
    "labels_path = find_combined_windows_json(NAB_ROOT)\n",
    "print(\"Found labels file:\", labels_path)\n",
    "\n",
    "with open(labels_path, \"r\") as f:\n",
    "    combined_windows = json.load(f)\n",
    "\n",
    "# Keys are like \"realAWSCloudwatch/ec2_cpu_utilization_53ea38.csv\"\n",
    "# We need to match the relative path style used by NAB.\n",
    "def infer_series_key(series_path: Path) -> str:\n",
    "    name = series_path.name\n",
    "    parent = series_path.parent.name  # expected: realAWSCloudwatch\n",
    "    return f\"{parent}/{name}\"\n",
    "\n",
    "series_key = infer_series_key(series_path)\n",
    "print(\"Series key guess:\", series_key)\n",
    "\n",
    "assert series_key in combined_windows, (\n",
    "    \"This series was not found in combined_windows.json.\\n\"\n",
    "    f\"Tried key: {series_key}\\n\"\n",
    "    \"If this happens, print keys and choose the right one.\"\n",
    ")\n",
    "\n",
    "windows = combined_windows[series_key]\n",
    "print(\"Number of labeled anomaly windows:\", len(windows))\n",
    "print(\"First 3 windows:\", windows[:3])"
   ],
   "id": "9a9cd7ef950d2c14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Build y_true vector (1 if timestamp inside any window)\n",
    "def build_labels(index_utc: pd.DatetimeIndex, windows) -> np.ndarray:\n",
    "    y = np.zeros(len(index_utc), dtype=int)\n",
    "    for w in windows:\n",
    "        start = pd.to_datetime(w[0], utc=True)\n",
    "        end = pd.to_datetime(w[1], utc=True)\n",
    "        y |= ((index_utc >= start) & (index_utc <= end)).astype(int)\n",
    "    return y\n",
    "\n",
    "# Ensure series index is UTC\n",
    "ts_utc = ts.copy()\n",
    "if ts_utc.index.tz is None:\n",
    "    ts_utc.index = ts_utc.index.tz_localize(\"UTC\")\n",
    "else:\n",
    "    ts_utc.index = ts_utc.index.tz_convert(\"UTC\")\n",
    "\n",
    "y_true = build_labels(ts_utc.index, windows)\n",
    "\n",
    "print(\"Total labeled anomaly points:\", int(y_true.sum()))"
   ],
   "id": "2d72a606a7d4d827"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Resample to regular frequency (helps both detection + forecasting)\n",
    "# Infer approximate frequency\n",
    "delta = ts_utc.index.to_series().diff().median()\n",
    "print(\"Median time delta:\", delta)\n",
    "\n",
    "# Choose a resample rule based on median delta\n",
    "# If it's around 5 minutes -> \"5min\", around 1 minute -> \"1min\", else fallback to median minutes\n",
    "minutes = max(1, int(round(delta.total_seconds() / 60))) if pd.notna(delta) else 5\n",
    "rule = f\"{minutes}min\"\n",
    "print(\"Resample rule:\", rule)\n",
    "\n",
    "ts_r = ts_utc[\"value\"].resample(rule).mean().interpolate(\"time\")\n",
    "y_r = pd.Series(y_true, index=ts_utc.index).resample(rule).max().fillna(0).astype(int).values\n",
    "\n",
    "df = pd.DataFrame({\"value\": ts_r.values, \"y_true\": y_r}, index=ts_r.index)\n",
    "df.head(), df[\"y_true\"].sum()"
   ],
   "id": "e405fd8ca68b1401"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Feature engineering for anomaly detection\n",
    "def make_features(series: pd.Series, window=12) -> pd.DataFrame:\n",
    "    X = pd.DataFrame({\"value\": series})\n",
    "    X[\"diff\"] = X[\"value\"].diff()\n",
    "    X[\"roll_mean\"] = X[\"value\"].rolling(window).mean()\n",
    "    X[\"roll_std\"] = X[\"value\"].rolling(window).std()\n",
    "    X = X.dropna()\n",
    "    return X\n",
    "\n",
    "X = make_features(df[\"value\"], window=12)\n",
    "y = df.loc[X.index, \"y_true\"].values\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y anomalies:\", int(y.sum()))"
   ],
   "id": "9e700033f4f26964"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#  Baseline detector (rolling z-score residual)\n",
    "resid = (X[\"value\"] - X[\"roll_mean\"]) / (X[\"roll_std\"] + 1e-8)\n",
    "Z_THRESHOLD = 3.0\n",
    "pred_baseline = (np.abs(resid.values) > Z_THRESHOLD).astype(int)\n",
    "\n",
    "baseline_metrics = {\n",
    "    \"precision\": precision_score(y, pred_baseline, zero_division=0),\n",
    "    \"recall\": recall_score(y, pred_baseline, zero_division=0),\n",
    "    \"f1\": f1_score(y, pred_baseline, zero_division=0),\n",
    "}\n",
    "baseline_metrics"
   ],
   "id": "4dc194a6923c7a77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# IsolationForest detector\n",
    "iso = IsolationForest(\n",
    "    n_estimators=300,\n",
    "    contamination=0.03,\n",
    "    random_state=42\n",
    ")\n",
    "iso.fit(X[[\"value\", \"diff\", \"roll_mean\", \"roll_std\"]])\n",
    "\n",
    "pred_iso = (iso.predict(X[[\"value\", \"diff\", \"roll_mean\", \"roll_std\"]]) == -1).astype(int)\n",
    "\n",
    "iso_metrics = {\n",
    "    \"precision\": precision_score(y, pred_iso, zero_division=0),\n",
    "    \"recall\": recall_score(y, pred_iso, zero_division=0),\n",
    "    \"f1\": f1_score(y, pred_iso, zero_division=0),\n",
    "}\n",
    "iso_metrics"
   ],
   "id": "5e63804d0c8ac9bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot detections (true anomalies vs predicted)\n",
    "plot_df = pd.DataFrame({\n",
    "    \"value\": X[\"value\"],\n",
    "    \"true_anom\": y,\n",
    "    \"baseline_anom\": pred_baseline,\n",
    "    \"iso_anom\": pred_iso\n",
    "}, index=X.index)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "plot_df[\"value\"].plot(ax=ax)\n",
    "ax.scatter(plot_df.index[plot_df[\"true_anom\"] == 1], plot_df.loc[plot_df[\"true_anom\"] == 1, \"value\"], marker=\"x\", label=\"True anomaly\")\n",
    "ax.scatter(plot_df.index[plot_df[\"iso_anom\"] == 1], plot_df.loc[plot_df[\"iso_anom\"] == 1, \"value\"], label=\"IsolationForest\")\n",
    "ax.set_title(f\"Anomaly Detection on {series_path.name}\")\n",
    "ax.set_xlabel(\"time\")\n",
    "ax.set_ylabel(\"value\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "ec8eadd9564c1b8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save metrics + plot + the resampled series\n",
    "comparison = pd.DataFrame([\n",
    "    {\"model\": \"baseline_zscore\", **baseline_metrics},\n",
    "    {\"model\": \"isolation_forest\", **iso_metrics},\n",
    "]).sort_values(\"f1\", ascending=False)\n",
    "\n",
    "metrics_out = ARTIFACTS_DIR / \"anomaly_metrics.json\"\n",
    "comparison.to_json(metrics_out, orient=\"records\", indent=2)\n",
    "\n",
    "data_out = DATA_DIR / f\"{series_path.stem}_resampled.csv\"\n",
    "df.to_csv(data_out, index=True)\n",
    "\n",
    "plot_out = IMAGES_DIR / \"anomaly_plot.png\"\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "plot_df[\"value\"].plot(ax=ax)\n",
    "ax.scatter(plot_df.index[plot_df[\"true_anom\"] == 1], plot_df.loc[plot_df[\"true_anom\"] == 1, \"value\"], marker=\"x\", label=\"True anomaly\")\n",
    "ax.scatter(plot_df.index[plot_df[\"iso_anom\"] == 1], plot_df.loc[plot_df[\"iso_anom\"] == 1, \"value\"], label=\"IsolationForest\")\n",
    "ax.set_title(f\"Anomaly Detection on {series_path.name}\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_out, dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved:\", metrics_out)\n",
    "print(\"Saved:\", data_out)\n",
    "print(\"Saved:\", plot_out)\n",
    "comparison"
   ],
   "id": "3bf535ed27c448f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create lag features\n",
    "def make_lagged_features(series: pd.Series, lags=24):\n",
    "    df_lag = pd.DataFrame({\"y\": series})\n",
    "    for i in range(1, lags + 1):\n",
    "        df_lag[f\"lag_{i}\"] = df_lag[\"y\"].shift(i)\n",
    "    df_lag = df_lag.dropna()\n",
    "    return df_lag\n",
    "\n",
    "LAGS = 24  # adjust based on your resample rule (e.g., 24 steps)\n",
    "lag_df = make_lagged_features(df[\"value\"], lags=LAGS)\n",
    "\n",
    "# Time-based split (no shuffling)\n",
    "split = int(len(lag_df) * 0.8)\n",
    "train = lag_df.iloc[:split]\n",
    "test = lag_df.iloc[split:]\n",
    "\n",
    "X_train, y_train = train.drop(columns=[\"y\"]), train[\"y\"]\n",
    "X_test, y_test = test.drop(columns=[\"y\"]), test[\"y\"]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ],
   "id": "5fe1a3d626840229"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Train a simple forecaster (Ridge regression)\n",
    "model = Ridge(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "rmse = mean_squared_error(y_test, pred, squared=False)\n",
    "\n",
    "print(\"Forecast MAE:\", mae)\n",
    "print(\"Forecast RMSE:\", rmse)"
   ],
   "id": "4e358ef262cd45aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot forecast vs actual\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "pd.Series(y_test.values, index=y_test.index).plot(ax=ax, label=\"Actual\")\n",
    "pd.Series(pred, index=y_test.index).plot(ax=ax, label=\"Forecast\")\n",
    "ax.set_title(\"Forecast vs Actual (Ridge + lag features)\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "e93e688fd898b52d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save forecast artifacts\n",
    "forecast_out = ARTIFACTS_DIR / \"forecast_metrics.json\"\n",
    "with open(forecast_out, \"w\") as f:\n",
    "    json.dump({\"mae\": float(mae), \"rmse\": float(rmse), \"lags\": LAGS, \"model\": \"Ridge\"}, f, indent=2)\n",
    "\n",
    "forecast_plot_out = IMAGES_DIR / \"forecast_plot.png\"\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "pd.Series(y_test.values, index=y_test.index).plot(ax=ax, label=\"Actual\")\n",
    "pd.Series(pred, index=y_test.index).plot(ax=ax, label=\"Forecast\")\n",
    "ax.set_title(\"Forecast vs Actual (Ridge + lag features)\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(forecast_plot_out, dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved:\", forecast_out)\n",
    "print(\"Saved:\", forecast_plot_out)"
   ],
   "id": "82d4caa5469cc77d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "693c2b99fb7d06b3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
